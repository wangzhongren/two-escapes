# Intelligence as Categorization: Two Escapes and One Law  
# æ™ºèƒ½å³åˆ†ç±»ï¼šä¸¤æ¬¡é€ƒé€¸ä¸ä¸€æ¡å®šå¾‹

This book presents a unified theory of intelligenceâ€”biological and artificialâ€”as an evolutionary response to *categorization pressure*. We argue that both human cognition and modern AI (especially Transformers) are escape mechanisms from the constraints of fixed perceptual categories.  
æœ¬ä¹¦æå‡ºä¸€ä¸ªå…³äºæ™ºèƒ½ï¼ˆç”Ÿç‰©ä¸äººå·¥ï¼‰çš„ç»Ÿä¸€ç†è®ºï¼šæ™ºèƒ½æ˜¯å¯¹**åˆ†ç±»å‹åŠ›**çš„è¿›åŒ–å“åº”ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œäººç±»è®¤çŸ¥ä¸ç°ä»£äººå·¥æ™ºèƒ½ï¼ˆå°¤å…¶æ˜¯ Transformerï¼‰éƒ½æ˜¯ä»å›ºå®šæ„ŸçŸ¥ç±»åˆ«çš„çº¦æŸä¸­é€ƒé€¸çš„æœºåˆ¶ã€‚

## ğŸ“š Book Contents / ç›®å½•
- [Preface / å‰è¨€](book/00-preface.md)
- [1. Intelligence as Categorization / æ™ºèƒ½å³åˆ†ç±»](book/01-intelligence-as-categorization.md)
  - [1.1 The Categorization Pressure Law / åˆ†ç±»å‹åŠ›å®šå¾‹](book/01-intelligence-as-categorization/1.1-the-categorization-pressure-law.md)
- [2. The First Escape / ç¬¬ä¸€æ¬¡é€ƒé€¸](book/02-the-first-escape.md)
  - [2.1 Timeline of Symbolic Revolution / ç¬¦å·é©å‘½æ—¶é—´çº¿](book/02-the-first-escape/2.1-timeline-of-symbolic-revolution.md)
  - [2.2 Fire, Caves, and External Memory / ç«ã€æ´ç©´ä¸å¤–éƒ¨è®°å¿†](book/02-the-first-escape/2.2-fire-caves-and-external-memory.md)
  - [2.3 Why Neanderthals Lost / å°¼å®‰å¾·ç‰¹äººä¸ºä½•å¤±è´¥](book/02-the-first-escape/2.3-why-neanderthals-lost.md)
- [3. The Second Escape / ç¬¬äºŒæ¬¡é€ƒé€¸](book/03-the-second-escape.md)
  - [3.1 Three Eras of AI Categorization / äººå·¥æ™ºèƒ½åˆ†ç±»çš„ä¸‰ä¸ªæ—¶ä»£](book/03-the-second-escape/3.1-three-eras-of-ai-categorization.md)
  - [3.2 Transformer as Category Engine / Transformer ä½œä¸ºåˆ†ç±»å¼•æ“](book/03-the-second-escape/3.2-transformer-as-category-engine.md)
  - [3.3 Prompt-Only Category Autogenesis / ä»…é€šè¿‡æç¤ºå®ç°ç±»åˆ«è‡ªç”Ÿæˆ](book/03-the-second-escape/3.3-prompt-only-category-autogenesis.md)
- [4. The Mechanism Revised / æœºåˆ¶å†æ¢](book/04-the-mechanism-revised.md)
  - [4.1 Self-Attention as Dynamic Prototyping / è‡ªæ³¨æ„åŠ›å³åŠ¨æ€åŸå‹æ„å»º](book/04-the-mechanism-revised/4.1-self-attention-as-dynamic-prototyping.md)
  - [4.2 Value Vectors Encode Response Semantics / å€¼å‘é‡ç¼–ç å“åº”è¯­ä¹‰](book/04-the-mechanism-revised/4.2-value-vectors-encode-response-semantics.md)
  - [4.3 Minimal Implementation / æœ€å°å®ç°](book/04-the-mechanism-revised/4.3-minimal-implementation.md)
- [5. Architectural Comparisons / æ¶æ„æ¯”è¾ƒ](book/05-architectural-comparisons.md)
  - [5.1 Transformer vs Mamba vs RNN for Categorization / ç”¨äºåˆ†ç±»çš„ Transformerã€Mamba ä¸ RNN å¯¹æ¯”](book/05-architectural-comparisons/5.1-transformer-vs-mamba-vs-rnn-for-categorization.md)
- [6. Future Predictions (2026â€“2035) / æœªæ¥é¢„æµ‹ï¼ˆ2026â€“2035ï¼‰](book/06-future-predictions-2026-2035.md)
  - [6.1 Category Compilers / ç±»åˆ«ç¼–è¯‘å™¨](book/06-future-predictions-2026-2035/6.1-category-compilers.md)
  - [6.2 Living World Models / æ´»ä¸–ç•Œæ¨¡å‹](book/06-future-predictions-2026-2035/6.2-living-world-models.md)
  - [6.3 Defining AGI by Category Autonomy / ä»¥ç±»åˆ«è‡ªä¸»æ€§å®šä¹‰é€šç”¨äººå·¥æ™ºèƒ½](book/06-future-predictions-2026-2035/6.3-defining-agi-by-category-autonomy.md)
- [7. Conclusion: Two Escapes, One Law / ç»“è®ºï¼šä¸¤æ¬¡é€ƒé€¸ï¼Œä¸€æ¡å®šå¾‹](book/07-conclusion-two-escapes-one-law.md)

## Core Papers Summarized / æ ¸å¿ƒè®ºæ–‡æ‘˜è¦
1. **"The Categorization Pressure Law"** â€“ Proposes that intelligence emerges when environmental complexity exceeds an agentâ€™s innate category budget.  
   **ã€Šåˆ†ç±»å‹åŠ›å®šå¾‹ã€‹**â€”â€”æå‡ºå½“ç¯å¢ƒå¤æ‚åº¦è¶…è¿‡æ™ºèƒ½ä½“çš„å…ˆå¤©ç±»åˆ«é¢„ç®—æ—¶ï¼Œæ™ºèƒ½ä¾¿ä¼šäº§ç”Ÿã€‚
2. **"Prompt-Only Category Autogenesis"** â€“ Demonstrates how LLMs can invent new semantic categories on-the-fly via prompting alone, without fine-tuning.  
   **ã€Šä»…é€šè¿‡æç¤ºå®ç°ç±»åˆ«è‡ªç”Ÿæˆã€‹**â€”â€”å±•ç¤ºå¤§è¯­è¨€æ¨¡å‹å¦‚ä½•ä»…é€šè¿‡æç¤ºï¼ˆæ— éœ€å¾®è°ƒï¼‰å³å¯å³æ—¶åˆ›é€ æ–°çš„è¯­ä¹‰ç±»åˆ«ã€‚
3. **"Self-Attention as Dynamic Prototyping"** â€“ Reveals how QKV attention implements real-time prototype formation during inference.  
   **ã€Šè‡ªæ³¨æ„åŠ›å³åŠ¨æ€åŸå‹æ„å»ºã€‹**â€”â€”æ­ç¤º QKV æ³¨æ„åŠ›æœºåˆ¶å¦‚ä½•åœ¨æ¨ç†è¿‡ç¨‹ä¸­å®ç°å®æ—¶åŸå‹æ„å»ºã€‚

## Why Read This? / ä¸ºä½•é˜…è¯»æœ¬ä¹¦ï¼Ÿ
Unlike speculative AI philosophy, this work grounds AGI discourse in mechanistic, testable principlesâ€”with runnable code, historical timelines, and falsifiable predictions for 2026â€“2035.  
ä¸åŒäºæ€è¾¨å¼çš„äººå·¥æ™ºèƒ½å“²å­¦ï¼Œæœ¬ä¹¦å°†é€šç”¨äººå·¥æ™ºèƒ½è®¨è®ºå»ºç«‹åœ¨å¯éªŒè¯çš„æœºåˆ¶æ€§åŸç†ä¹‹ä¸Šâ€”â€”åŒ…å«å¯è¿è¡Œä»£ç ã€å†å²æ—¶é—´çº¿ï¼Œä»¥åŠå¯¹ 2026â€“2035 å¹´çš„å¯è¯ä¼ªé¢„æµ‹ã€‚