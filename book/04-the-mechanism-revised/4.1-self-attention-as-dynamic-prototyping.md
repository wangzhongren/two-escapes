# 4.1 自注意力即动态原型构建

## 原型理论回顾

在认知科学中，**原型（Prototype）** 是某类别的最佳范例（如“知更鸟”之于“鸟”），而非逻辑定义。人类通过相似度匹配进行分类。

## Transformer 的原型机制

在标准自注意力中：
- 每个token的 **Key** 向量 = 其作为“潜在原型”的身份标识
- 每个token的 **Value** 向量 = 若被选为原型，应输出的语义响应

当新输入（Query）到来：
1. 计算其与所有Keys的相似度 → 确定哪些上下文token可作为原型
2. 加权聚合对应Values → 生成针对当前Query的定制化响应

> 这不是检索，而是**即时协商一个临时类别共识**。

## 示例：代词消解

句子：“张三告诉李四他赢了。”

- “他”的Query向量激活“张三”和“李四”的Keys
- 根据上下文权重，主要聚合“张三”的Value（因主语优先）
- 输出反映“张三赢了”的语义

**关键洞见**：Value并非“信息”，而是“对此类别的恰当反应”。