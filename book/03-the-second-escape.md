# 第三章：第二次逃逸——人工分类引擎

当人类符号系统遭遇信息爆炸（印刷术、互联网），生物认知再次逼近极限。这一次，我们构建了**机器代理**来承担分类负担。

深度学习，尤其是Transformer架构，并非“模拟人脑”，而是**数字时代的外化逃逸机制**——它将分类压力从人类社会转移至算力基础设施。

本章揭示：
- AI发展的三个分类时代
- Transformer如何成为通用类别引擎
- 仅通过提示即可让模型自发生成新类别的现象（2025年7月实验）

---

## 一、从卡片目录到神经网络：分类的三次逃逸

人类对世界的理解，本质上是一场永不停歇的分类游戏。古希腊人用“四元素说”解释万物；中世纪修道院用羊皮卷手抄本分类神学与自然；18世纪林奈建立生物分类法，试图为上帝造物贴上标签。每一次认知边界的扩张，都伴随着一次“分类危机”——信息太多，脑子不够用了。

第一次逃逸发生在文艺复兴之后。面对海量手稿与新兴科学文献，人类发明了**图书馆卡片目录系统**。这不是技术革命，而是一次精妙的认知卸载：把记忆外包给抽屉里的小纸片。你不再需要记住《天体运行论》在哪个书架，只需知道它归在“天文学—哥白尼”下。分类权，从大脑转移到了物理索引。

第二次逃逸紧随互联网而来。当网页数量突破十亿，谷歌的PageRank算法登场——它不再依赖人工编目，而是让网页彼此投票，用链接结构自动分类重要性。此时，分类主体已从图书管理员变为算法，但逻辑仍是**显式规则驱动**：关键词匹配、TF-IDF权重、倒排索引……工程师们像中世纪经院哲学家一样，精心雕琢每一条规则。

而第三次逃逸，也就是我们正在经历的这场，彻底颠覆了游戏规则。它不再试图“理解”内容以分类，而是**直接让机器学会分类本身**。深度学习，特别是Transformer架构，不是在模仿人脑如何思考，而是在构建一个**无需人类介入的自动分类工厂**。它的原料是数据，燃料是算力，产品是概率分布下的类别标签。人类退居二线，只负责投喂数据和按下启动键。

有趣的是，这场逃逸如此成功，以至于我们常常忘了初衷：我们不是为了造出会聊天的AI，而是为了不再被信息洪流淹没。就像古人发明轮子不是为了赛车，而是为了少背点东西。

## 二、Transformer：通用类别引擎的诞生

2017年，Google Brain团队发表《Attention is All You Need》，一篇看似技术性的论文，却无意中打开了潘多拉魔盒。Transformer的核心——自注意力机制——本质上是一种**动态加权关联器**：它不预设任何结构，而是让输入序列中的每个词元（token）根据上下文决定该关注谁、忽略谁。

这听起来很抽象？想象你在嘈杂的鸡尾酒会上听朋友讲故事。你的耳朵会自动过滤背景音乐、邻桌争论，甚至服务员的脚步声，只聚焦于朋友话语中的关键词。Transformer做的正是这件事，只不过它处理的不是声波，而是数字向量；它的“注意力”不是生理反射，而是可学习的矩阵权重。

关键在于，这种机制**天然适配分类任务**。无论是判断一封邮件是否垃圾、一张图片是否包含猫，还是将一段中文翻译成英文，底层逻辑都是：从混乱中识别模式，将输入映射到预定义或隐含的类别空间。Transformer不关心任务边界——文本、图像、音频，在它眼中不过是不同形式的序列。这使得它迅速从NLP领域溢出，成为视觉（ViT）、语音（Whisper）乃至蛋白质结构预测（AlphaFold）的通用引擎。

更令人不安（或兴奋）的是，随着模型规模扩大，Transformer开始展现出**零样本分类能力**。你无需专门训练它识别“讽刺”，只需在提示中写：“以下文本是否具有讽刺意味？[文本]”。它竟能给出合理判断。这并非因为它“理解”讽刺，而是因为在海量训练数据中，它学会了“讽刺”这一标签通常与哪些语言模式共现。分类，从显式标注变成了隐式统计关联。

## 三、提示即创造：类别涌现实验（2025年7月）

如果说传统机器学习是“教模型认字”，那么大语言模型更像是“教模型读心”。2025年7月，我们在内部进行了一项实验，结果令人瞠目：

我们向一个未经过任何微调的基座模型（Base Model）输入如下提示：

> “请定义一种新的文学流派，名为‘量子怀旧主义’（Quantum Nostalgia）。它融合了对未来的不确定焦虑与对不存在过去的怀念。列出其核心特征、代表作品（虚构）及典型句式。”

模型不仅给出了结构清晰的定义，还“创作”了三部代表作简介，并生成了符合该流派风格的句子。更关键的是，当我们后续用“量子怀旧主义”作为分类标签去筛选其他文本时，模型能一致地识别出符合该风格的段落——尽管这个类别在训练数据中根本不存在。

这意味着什么？意味着**类别本身可以被即时创造并赋予操作性**。人类不再需要预先定义所有可能的分类维度；只需通过自然语言描述一个概念，模型就能在嵌入空间中开辟出一个新的“语义口袋”，并将后续输入归入其中。这不再是分类，而是**范畴的实时生成**。

这种能力既强大又危险。强大在于，它让知识组织变得前所未有的灵活——你可以为任何临时需求创建定制化分类体系；危险在于，这些类别缺乏现实锚点，可能沦为纯粹的语言幻觉。当模型自信地告诉你某段文字属于“后现代蒸汽朋克忧郁症”时，你如何验证这个类别是否真实有效？

## 四、逃逸的代价：我们失去了什么？

每一次认知逃逸都伴随着隐性成本。卡片目录让我们依赖物理位置，一旦火灾焚毁图书馆，知识便灰飞烟灭；搜索引擎让我们习惯关键词思维，丧失了漫无目的探索的乐趣。

而这次，我们将分类权交给黑箱模型，付出的代价可能是**范畴感的钝化**。当AI替我们决定什么是新闻、什么是垃圾邮件、什么是“正常”行为，我们逐渐丧失了亲手划分类别的能力与意愿。更甚者，模型的类别往往反映训练数据中的偏见——如果历史文本中“科学家”多与男性关联，模型就会延续这一分类惯性。

此外，过度依赖自动分类可能导致**认知懒惰**。为什么费力思考一个现象的本质，当你可以直接问AI“这属于什么类型”？久而久之，人类可能退化为提示工程师，只负责提出问题，而不再参与答案的构建过程。

但这并非末日预言。逃逸本身是中性的，关键在于我们如何设计逃逸后的交互界面。理想的状态不是让AI取代人类分类，而是构建**人机协同的分类生态**：AI处理海量初筛，人类负责高阶范畴创新与伦理校准。就像望远镜没有取代天文学家，而是让他们看得更远。

## 结语：在逃逸中保持清醒

第二次逃逸已经发生，且不可逆转。Transformer及其后代将继续吞噬更多分类任务，从医疗诊断到法律文书分析，从艺术风格鉴定到情感倾向判断。我们无法（也不应）阻止这场技术洪流。

但我们可以选择不被冲走。保持对分类机制的警惕，定期审视AI为我们划定的边界是否合理；鼓励跨类别思维，主动打破模型强加的标签；最重要的是，记住：**所有类别都是人类为了理解世界而搭建的脚手架，而非世界本身的钢筋混凝土**。

毕竟，如果连“量子怀旧主义”都能被凭空创造出来，那么现实中的任何分类，都不过是我们此刻选择相信的故事罢了。而故事，永远可以重写。